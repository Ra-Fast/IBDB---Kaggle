{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDMB Data\n",
    "https://www.kaggle.com/datasets/mahmoudshaheen1134/imdp-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycaret.classification import *\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(file_path, sample_size=None):\n",
    "    \"\"\"\n",
    "    Load and prepare the IMDB dataset with text preprocessing\n",
    "    \"\"\"\n",
    "    # Download required NLTK data\n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "    # Read the dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Take a sample if specified (useful for quick testing)\n",
    "    if sample_size:\n",
    "        df = df.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Create TF-IDF features with stopword removal\n",
    "    tfidf = TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        max_features=5000,\n",
    "        strip_accents='unicode',\n",
    "        lowercase=True\n",
    "    )\n",
    "    \n",
    "    # Transform the text data\n",
    "    text_features = tfidf.fit_transform(df['review'])\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    feature_names = tfidf.get_feature_names_out()\n",
    "    text_df = pd.DataFrame(text_features.toarray(), columns=feature_names)\n",
    "    \n",
    "    # Combine with target variable\n",
    "    final_df = pd.concat([text_df, df['sentiment']], axis=1)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_pycaret_classifier(data):\n",
    "    \"\"\"\n",
    "    Setup PyCaret classification experiment\n",
    "    \"\"\"\n",
    "    # Initialize setup with minimal parameters\n",
    "    clf_setup = setup(\n",
    "        data=data,\n",
    "        target='sentiment',\n",
    "        session_id=42,\n",
    "        preprocess=True\n",
    "    )\n",
    "    return clf_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_models(top_n=3):\n",
    "    \"\"\"\n",
    "    Get the best performing models\n",
    "    \"\"\"\n",
    "    print(f\"\\nTraining and selecting top {top_n} models...\")\n",
    "    best_models = compare_models(\n",
    "        n_select=top_n,\n",
    "        sort='F1' # Using F1 as initial metric since it balances Precision and Recall\n",
    "    )\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_models(models):\n",
    "    \"\"\"\n",
    "    Fine-tune each model using PyCaret's tune_model function\n",
    "    Optimizing for both Precision and Recall\n",
    "    \"\"\"\n",
    "    print(\"\\nTuning individual models...\")\n",
    "    tuned_models = []\n",
    "    \n",
    "    for i, model in enumerate(models, 1):\n",
    "        print(f\"\\nTuning model {i}...\")\n",
    "        \n",
    "        # Print available metrics before tuning\n",
    "        print(\"\\nAvailable metrics before tuning:\")\n",
    "        initial_metrics = pull()\n",
    "        print(initial_metrics.columns.tolist())\n",
    "        \n",
    "        # First tune for Recall\n",
    "        print(f\"\\nTuning for Recall...\")\n",
    "        recall_tuned = tune_model(\n",
    "            model,\n",
    "            n_iter=10,\n",
    "            optimize='Recall',\n",
    "            search_library='optuna',\n",
    "            choose_better=True\n",
    "        )\n",
    "        \n",
    "        # Then tune for Precision\n",
    "        print(f\"\\nTuning for Precision...\")\n",
    "        precision_tuned = tune_model(\n",
    "            recall_tuned,\n",
    "            n_iter=10,\n",
    "            optimize='Prec.',  # or whatever the actual precision metric name is\n",
    "            search_library='optuna',\n",
    "            choose_better=True\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nModel {i} tuning completed\")\n",
    "        \n",
    "        # Print final metrics\n",
    "        print(\"\\nFinal metrics after tuning:\")\n",
    "        eval_metrics = pull()\n",
    "        for metric in eval_metrics.columns:\n",
    "            try:\n",
    "                print(f\"{metric}: {eval_metrics.loc[0, metric]:.4f}\")\n",
    "            except:\n",
    "                print(f\"{metric}: {eval_metrics.loc[0, metric]}\")\n",
    "        \n",
    "        tuned_models.append(precision_tuned)\n",
    "    \n",
    "    return tuned_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble(tuned_models):\n",
    "    \"\"\"\n",
    "    Create a stacking ensemble from the tuned models\n",
    "    \"\"\"\n",
    "    print(\"\\nCreating stacking ensemble...\")\n",
    "    \n",
    "    # Create stacking ensemble\n",
    "    stacker = stack_models(\n",
    "        estimator_list=tuned_models,\n",
    "        meta_model='lr',  # Using logistic regression as meta-model\n",
    "        restack=True  # Use predictions from base models as features\n",
    "    )\n",
    "    \n",
    "    return stacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Evaluate model performance with focus on Precision and Recall\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    \n",
    "    # Get model predictions\n",
    "    predictions = predict_model(model)\n",
    "    \n",
    "    # Create evaluation plots\n",
    "    try:\n",
    "        plot_model(model, plot='confusion_matrix')\n",
    "        plot_model(model, plot='pr')  # Precision-Recall curve\n",
    "    except:\n",
    "        print(\"Warning: Could not create some plots\")\n",
    "    \n",
    "    # Print detailed metrics\n",
    "    try:\n",
    "        metrics = pull()\n",
    "        print(\"\\nDetailed Metrics:\")\n",
    "        \n",
    "        # Get the actual column names from the metrics DataFrame\n",
    "        metric_columns = metrics.columns\n",
    "        \n",
    "        # Print available metrics\n",
    "        for metric in metric_columns:\n",
    "            try:\n",
    "                print(f\"{metric}: {metrics.loc[0, metric]:.4f}\")\n",
    "            except:\n",
    "                print(f\"{metric}: {metrics.loc[0, metric]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting metrics: {str(e)}\")\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_performances(tuned_models, ensemble_model):\n",
    "    \"\"\"\n",
    "    Compare performance of individual models against ensemble\n",
    "    \"\"\"\n",
    "    print(\"\\n=== PERFORMANCE COMPARISON ===\")\n",
    "    print(\"\\nIndividual Models Performance:\")\n",
    "    \n",
    "    # Store metrics for comparison\n",
    "    all_metrics = []\n",
    "    \n",
    "    # Evaluate individual models\n",
    "    for i, model in enumerate(tuned_models, 1):\n",
    "        print(f\"\\nModel {i}:\")\n",
    "        predictions = predict_model(model)\n",
    "        metrics = pull()\n",
    "        all_metrics.append(metrics.iloc[0].to_dict())\n",
    "        \n",
    "        # Print all available metrics\n",
    "        for col in metrics.columns:\n",
    "            try:\n",
    "                print(f\"{col}: {metrics.iloc[0][col]:.4f}\")\n",
    "            except:\n",
    "                print(f\"{col}: {metrics.iloc[0][col]}\")\n",
    "    \n",
    "    # Evaluate ensemble\n",
    "    print(\"\\nEnsemble Model Performance:\")\n",
    "    ensemble_predictions = predict_model(ensemble_model)\n",
    "    ensemble_metrics = pull()\n",
    "    \n",
    "    # Print all available metrics for ensemble\n",
    "    for col in ensemble_metrics.columns:\n",
    "        try:\n",
    "            print(f\"{col}: {ensemble_metrics.iloc[0][col]:.4f}\")\n",
    "        except:\n",
    "            print(f\"{col}: {ensemble_metrics.iloc[0][col]}\")\n",
    "    \n",
    "    # Compare with best individual model\n",
    "    print(\"\\n=== COMPARISON WITH BEST INDIVIDUAL MODEL ===\")\n",
    "    for col in ensemble_metrics.columns:\n",
    "        if col in all_metrics[0]:  # Check if metric exists in individual models\n",
    "            best_individual = max(m[col] for m in all_metrics if isinstance(m[col], (int, float)))\n",
    "            ensemble_value = ensemble_metrics.iloc[0][col]\n",
    "            \n",
    "            try:\n",
    "                print(f\"{col}:\")\n",
    "                print(f\"Best Individual: {best_individual:.4f}\")\n",
    "                print(f\"Ensemble: {ensemble_value:.4f}\")\n",
    "                if isinstance(ensemble_value, (int, float)):\n",
    "                    improvement = ((ensemble_value - best_individual) / best_individual) * 100\n",
    "                    print(f\"Improvement: {improvement:.2f}%\")\n",
    "                print()\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    return ensemble_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\erafpac\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyCaret classifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0d0f5_row9_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0d0f5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0d0f5_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_0d0f5_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0d0f5_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_0d0f5_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0d0f5_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_0d0f5_row1_col1\" class=\"data row1 col1\" >sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0d0f5_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_0d0f5_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_0d0f5_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
       "      <td id=\"T_0d0f5_row3_col1\" class=\"data row3 col1\" >negative: 0, positive: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_0d0f5_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_0d0f5_row4_col1\" class=\"data row4 col1\" >(50000, 5001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_0d0f5_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_0d0f5_row5_col1\" class=\"data row5 col1\" >(50000, 5001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_0d0f5_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_0d0f5_row6_col1\" class=\"data row6 col1\" >(35000, 5001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_0d0f5_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_0d0f5_row7_col1\" class=\"data row7 col1\" >(15000, 5001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_0d0f5_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_0d0f5_row8_col1\" class=\"data row8 col1\" >5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_0d0f5_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_0d0f5_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_0d0f5_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_0d0f5_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_0d0f5_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_0d0f5_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_0d0f5_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_0d0f5_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_0d0f5_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_0d0f5_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_0d0f5_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_0d0f5_row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_0d0f5_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_0d0f5_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_0d0f5_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_0d0f5_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_0d0f5_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_0d0f5_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_0d0f5_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_0d0f5_row18_col1\" class=\"data row18 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d0f5_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_0d0f5_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_0d0f5_row19_col1\" class=\"data row19 col1\" >170d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2045f742050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and selecting top 3 models...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>22:26:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Fitting 10 Folds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>CatBoost Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   \n",
       "                                                                   \n",
       "Initiated  . . . . . . . . . . . . . . . . . .             22:26:45\n",
       "Status     . . . . . . . . . . . . . . . . . .     Fitting 10 Folds\n",
       "Estimator  . . . . . . . . . . . . . . . . . .  CatBoost Classifier"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_44f1c th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_44f1c_row0_col0, #T_44f1c_row0_col1, #T_44f1c_row0_col2, #T_44f1c_row0_col3, #T_44f1c_row0_col4, #T_44f1c_row0_col5, #T_44f1c_row0_col6, #T_44f1c_row0_col7, #T_44f1c_row0_col8, #T_44f1c_row1_col0, #T_44f1c_row1_col1, #T_44f1c_row1_col2, #T_44f1c_row1_col3, #T_44f1c_row1_col4, #T_44f1c_row1_col5, #T_44f1c_row1_col6, #T_44f1c_row1_col7, #T_44f1c_row1_col8, #T_44f1c_row2_col0, #T_44f1c_row2_col1, #T_44f1c_row2_col2, #T_44f1c_row2_col3, #T_44f1c_row2_col4, #T_44f1c_row2_col5, #T_44f1c_row2_col6, #T_44f1c_row2_col7, #T_44f1c_row2_col8, #T_44f1c_row3_col0, #T_44f1c_row3_col1, #T_44f1c_row3_col2, #T_44f1c_row3_col3, #T_44f1c_row3_col4, #T_44f1c_row3_col5, #T_44f1c_row3_col6, #T_44f1c_row3_col7, #T_44f1c_row3_col8, #T_44f1c_row4_col0, #T_44f1c_row4_col1, #T_44f1c_row4_col2, #T_44f1c_row4_col3, #T_44f1c_row4_col4, #T_44f1c_row4_col5, #T_44f1c_row4_col6, #T_44f1c_row4_col7, #T_44f1c_row4_col8, #T_44f1c_row5_col0, #T_44f1c_row5_col1, #T_44f1c_row5_col2, #T_44f1c_row5_col3, #T_44f1c_row5_col4, #T_44f1c_row5_col5, #T_44f1c_row5_col6, #T_44f1c_row5_col7, #T_44f1c_row5_col8, #T_44f1c_row6_col0, #T_44f1c_row6_col1, #T_44f1c_row6_col2, #T_44f1c_row6_col3, #T_44f1c_row6_col4, #T_44f1c_row6_col5, #T_44f1c_row6_col6, #T_44f1c_row6_col7, #T_44f1c_row6_col8, #T_44f1c_row7_col0, #T_44f1c_row7_col1, #T_44f1c_row7_col2, #T_44f1c_row7_col3, #T_44f1c_row7_col4, #T_44f1c_row7_col5, #T_44f1c_row7_col6, #T_44f1c_row7_col7, #T_44f1c_row7_col8, #T_44f1c_row8_col0, #T_44f1c_row8_col1, #T_44f1c_row8_col2, #T_44f1c_row8_col3, #T_44f1c_row8_col4, #T_44f1c_row8_col5, #T_44f1c_row8_col6, #T_44f1c_row8_col7, #T_44f1c_row8_col8, #T_44f1c_row9_col0, #T_44f1c_row9_col1, #T_44f1c_row9_col2, #T_44f1c_row9_col3, #T_44f1c_row9_col4, #T_44f1c_row9_col5, #T_44f1c_row9_col6, #T_44f1c_row9_col7, #T_44f1c_row9_col8, #T_44f1c_row10_col0, #T_44f1c_row10_col1, #T_44f1c_row10_col2, #T_44f1c_row10_col3, #T_44f1c_row10_col4, #T_44f1c_row10_col5, #T_44f1c_row10_col6, #T_44f1c_row10_col7, #T_44f1c_row10_col8, #T_44f1c_row11_col0, #T_44f1c_row11_col1, #T_44f1c_row11_col2, #T_44f1c_row11_col3, #T_44f1c_row11_col4, #T_44f1c_row11_col5, #T_44f1c_row11_col6, #T_44f1c_row11_col7, #T_44f1c_row11_col8, #T_44f1c_row12_col0, #T_44f1c_row12_col1, #T_44f1c_row12_col2, #T_44f1c_row12_col3, #T_44f1c_row12_col4, #T_44f1c_row12_col5, #T_44f1c_row12_col6, #T_44f1c_row12_col7, #T_44f1c_row12_col8 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_44f1c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_44f1c_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_44f1c_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_44f1c_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_44f1c_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_44f1c_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_44f1c_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_44f1c_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_44f1c_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_44f1c_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_44f1c_level0_row0\" class=\"row_heading level0 row0\" >lr</th>\n",
       "      <td id=\"T_44f1c_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_44f1c_row0_col1\" class=\"data row0 col1\" >0.8840</td>\n",
       "      <td id=\"T_44f1c_row0_col2\" class=\"data row0 col2\" >0.9526</td>\n",
       "      <td id=\"T_44f1c_row0_col3\" class=\"data row0 col3\" >0.8840</td>\n",
       "      <td id=\"T_44f1c_row0_col4\" class=\"data row0 col4\" >0.8843</td>\n",
       "      <td id=\"T_44f1c_row0_col5\" class=\"data row0 col5\" >0.8840</td>\n",
       "      <td id=\"T_44f1c_row0_col6\" class=\"data row0 col6\" >0.7680</td>\n",
       "      <td id=\"T_44f1c_row0_col7\" class=\"data row0 col7\" >0.7683</td>\n",
       "      <td id=\"T_44f1c_row0_col8\" class=\"data row0 col8\" >12.3510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44f1c_level0_row1\" class=\"row_heading level0 row1\" >svm</th>\n",
       "      <td id=\"T_44f1c_row1_col0\" class=\"data row1 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_44f1c_row1_col1\" class=\"data row1 col1\" >0.8785</td>\n",
       "      <td id=\"T_44f1c_row1_col2\" class=\"data row1 col2\" >0.9522</td>\n",
       "      <td id=\"T_44f1c_row1_col3\" class=\"data row1 col3\" >0.8785</td>\n",
       "      <td id=\"T_44f1c_row1_col4\" class=\"data row1 col4\" >0.8811</td>\n",
       "      <td id=\"T_44f1c_row1_col5\" class=\"data row1 col5\" >0.8783</td>\n",
       "      <td id=\"T_44f1c_row1_col6\" class=\"data row1 col6\" >0.7570</td>\n",
       "      <td id=\"T_44f1c_row1_col7\" class=\"data row1 col7\" >0.7596</td>\n",
       "      <td id=\"T_44f1c_row1_col8\" class=\"data row1 col8\" >211.1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44f1c_level0_row2\" class=\"row_heading level0 row2\" >ridge</th>\n",
       "      <td id=\"T_44f1c_row2_col0\" class=\"data row2 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_44f1c_row2_col1\" class=\"data row2 col1\" >0.8754</td>\n",
       "      <td id=\"T_44f1c_row2_col2\" class=\"data row2 col2\" >0.9467</td>\n",
       "      <td id=\"T_44f1c_row2_col3\" class=\"data row2 col3\" >0.8754</td>\n",
       "      <td id=\"T_44f1c_row2_col4\" class=\"data row2 col4\" >0.8757</td>\n",
       "      <td id=\"T_44f1c_row2_col5\" class=\"data row2 col5\" >0.8753</td>\n",
       "      <td id=\"T_44f1c_row2_col6\" class=\"data row2 col6\" >0.7507</td>\n",
       "      <td id=\"T_44f1c_row2_col7\" class=\"data row2 col7\" >0.7511</td>\n",
       "      <td id=\"T_44f1c_row2_col8\" class=\"data row2 col8\" >7.8420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44f1c_level0_row3\" class=\"row_heading level0 row3\" >lda</th>\n",
       "      <td id=\"T_44f1c_row3_col0\" class=\"data row3 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_44f1c_row3_col1\" class=\"data row3 col1\" >0.8641</td>\n",
       "      <td id=\"T_44f1c_row3_col2\" class=\"data row3 col2\" >0.9378</td>\n",
       "      <td id=\"T_44f1c_row3_col3\" class=\"data row3 col3\" >0.8641</td>\n",
       "      <td id=\"T_44f1c_row3_col4\" class=\"data row3 col4\" >0.8643</td>\n",
       "      <td id=\"T_44f1c_row3_col5\" class=\"data row3 col5\" >0.8641</td>\n",
       "      <td id=\"T_44f1c_row3_col6\" class=\"data row3 col6\" >0.7282</td>\n",
       "      <td id=\"T_44f1c_row3_col7\" class=\"data row3 col7\" >0.7284</td>\n",
       "      <td id=\"T_44f1c_row3_col8\" class=\"data row3 col8\" >58.4270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44f1c_level0_row4\" class=\"row_heading level0 row4\" >et</th>\n",
       "      <td id=\"T_44f1c_row4_col0\" class=\"data row4 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_44f1c_row4_col1\" class=\"data row4 col1\" >0.8628</td>\n",
       "      <td id=\"T_44f1c_row4_col2\" class=\"data row4 col2\" >0.9360</td>\n",
       "      <td id=\"T_44f1c_row4_col3\" class=\"data row4 col3\" >0.8628</td>\n",
       "      <td id=\"T_44f1c_row4_col4\" class=\"data row4 col4\" >0.8631</td>\n",
       "      <td id=\"T_44f1c_row4_col5\" class=\"data row4 col5\" >0.8627</td>\n",
       "      <td id=\"T_44f1c_row4_col6\" class=\"data row4 col6\" >0.7255</td>\n",
       "      <td id=\"T_44f1c_row4_col7\" class=\"data row4 col7\" >0.7259</td>\n",
       "      <td id=\"T_44f1c_row4_col8\" class=\"data row4 col8\" >46.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44f1c_level0_row5\" class=\"row_heading level0 row5\" >lightgbm</th>\n",
       "      <td id=\"T_44f1c_row5_col0\" class=\"data row5 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_44f1c_row5_col1\" class=\"data row5 col1\" >0.8554</td>\n",
       "      <td id=\"T_44f1c_row5_col2\" class=\"data row5 col2\" >0.9345</td>\n",
       "      <td id=\"T_44f1c_row5_col3\" class=\"data row5 col3\" >0.8554</td>\n",
       "      <td id=\"T_44f1c_row5_col4\" class=\"data row5 col4\" >0.8558</td>\n",
       "      <td id=\"T_44f1c_row5_col5\" class=\"data row5 col5\" >0.8554</td>\n",
       "      <td id=\"T_44f1c_row5_col6\" class=\"data row5 col6\" >0.7109</td>\n",
       "      <td id=\"T_44f1c_row5_col7\" class=\"data row5 col7\" >0.7112</td>\n",
       "      <td id=\"T_44f1c_row5_col8\" class=\"data row5 col8\" >20.5640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44f1c_level0_row6\" class=\"row_heading level0 row6\" >rf</th>\n",
       "      <td id=\"T_44f1c_row6_col0\" class=\"data row6 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_44f1c_row6_col1\" class=\"data row6 col1\" >0.8456</td>\n",
       "      <td id=\"T_44f1c_row6_col2\" class=\"data row6 col2\" >0.9240</td>\n",
       "      <td id=\"T_44f1c_row6_col3\" class=\"data row6 col3\" >0.8456</td>\n",
       "      <td id=\"T_44f1c_row6_col4\" class=\"data row6 col4\" >0.8458</td>\n",
       "      <td id=\"T_44f1c_row6_col5\" class=\"data row6 col5\" >0.8455</td>\n",
       "      <td id=\"T_44f1c_row6_col6\" class=\"data row6 col6\" >0.6911</td>\n",
       "      <td id=\"T_44f1c_row6_col7\" class=\"data row6 col7\" >0.6914</td>\n",
       "      <td id=\"T_44f1c_row6_col8\" class=\"data row6 col8\" >25.3910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44f1c_level0_row7\" class=\"row_heading level0 row7\" >gbc</th>\n",
       "      <td id=\"T_44f1c_row7_col0\" class=\"data row7 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_44f1c_row7_col1\" class=\"data row7 col1\" >0.8054</td>\n",
       "      <td id=\"T_44f1c_row7_col2\" class=\"data row7 col2\" >0.8918</td>\n",
       "      <td id=\"T_44f1c_row7_col3\" class=\"data row7 col3\" >0.8054</td>\n",
       "      <td id=\"T_44f1c_row7_col4\" class=\"data row7 col4\" >0.8100</td>\n",
       "      <td id=\"T_44f1c_row7_col5\" class=\"data row7 col5\" >0.8047</td>\n",
       "      <td id=\"T_44f1c_row7_col6\" class=\"data row7 col6\" >0.6109</td>\n",
       "      <td id=\"T_44f1c_row7_col7\" class=\"data row7 col7\" >0.6154</td>\n",
       "      <td id=\"T_44f1c_row7_col8\" class=\"data row7 col8\" >75.0850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44f1c_level0_row8\" class=\"row_heading level0 row8\" >nb</th>\n",
       "      <td id=\"T_44f1c_row8_col0\" class=\"data row8 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_44f1c_row8_col1\" class=\"data row8 col1\" >0.7994</td>\n",
       "      <td id=\"T_44f1c_row8_col2\" class=\"data row8 col2\" >0.8442</td>\n",
       "      <td id=\"T_44f1c_row8_col3\" class=\"data row8 col3\" >0.7994</td>\n",
       "      <td id=\"T_44f1c_row8_col4\" class=\"data row8 col4\" >0.7995</td>\n",
       "      <td id=\"T_44f1c_row8_col5\" class=\"data row8 col5\" >0.7994</td>\n",
       "      <td id=\"T_44f1c_row8_col6\" class=\"data row8 col6\" >0.5988</td>\n",
       "      <td id=\"T_44f1c_row8_col7\" class=\"data row8 col7\" >0.5989</td>\n",
       "      <td id=\"T_44f1c_row8_col8\" class=\"data row8 col8\" >7.3570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44f1c_level0_row9\" class=\"row_heading level0 row9\" >ada</th>\n",
       "      <td id=\"T_44f1c_row9_col0\" class=\"data row9 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_44f1c_row9_col1\" class=\"data row9 col1\" >0.7988</td>\n",
       "      <td id=\"T_44f1c_row9_col2\" class=\"data row9 col2\" >0.8803</td>\n",
       "      <td id=\"T_44f1c_row9_col3\" class=\"data row9 col3\" >0.7988</td>\n",
       "      <td id=\"T_44f1c_row9_col4\" class=\"data row9 col4\" >0.8014</td>\n",
       "      <td id=\"T_44f1c_row9_col5\" class=\"data row9 col5\" >0.7983</td>\n",
       "      <td id=\"T_44f1c_row9_col6\" class=\"data row9 col6\" >0.5975</td>\n",
       "      <td id=\"T_44f1c_row9_col7\" class=\"data row9 col7\" >0.6002</td>\n",
       "      <td id=\"T_44f1c_row9_col8\" class=\"data row9 col8\" >21.8620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44f1c_level0_row10\" class=\"row_heading level0 row10\" >knn</th>\n",
       "      <td id=\"T_44f1c_row10_col0\" class=\"data row10 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_44f1c_row10_col1\" class=\"data row10 col1\" >0.7229</td>\n",
       "      <td id=\"T_44f1c_row10_col2\" class=\"data row10 col2\" >0.7832</td>\n",
       "      <td id=\"T_44f1c_row10_col3\" class=\"data row10 col3\" >0.7229</td>\n",
       "      <td id=\"T_44f1c_row10_col4\" class=\"data row10 col4\" >0.7230</td>\n",
       "      <td id=\"T_44f1c_row10_col5\" class=\"data row10 col5\" >0.7229</td>\n",
       "      <td id=\"T_44f1c_row10_col6\" class=\"data row10 col6\" >0.4459</td>\n",
       "      <td id=\"T_44f1c_row10_col7\" class=\"data row10 col7\" >0.4460</td>\n",
       "      <td id=\"T_44f1c_row10_col8\" class=\"data row10 col8\" >33.1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44f1c_level0_row11\" class=\"row_heading level0 row11\" >dt</th>\n",
       "      <td id=\"T_44f1c_row11_col0\" class=\"data row11 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_44f1c_row11_col1\" class=\"data row11 col1\" >0.7177</td>\n",
       "      <td id=\"T_44f1c_row11_col2\" class=\"data row11 col2\" >0.7177</td>\n",
       "      <td id=\"T_44f1c_row11_col3\" class=\"data row11 col3\" >0.7177</td>\n",
       "      <td id=\"T_44f1c_row11_col4\" class=\"data row11 col4\" >0.7178</td>\n",
       "      <td id=\"T_44f1c_row11_col5\" class=\"data row11 col5\" >0.7176</td>\n",
       "      <td id=\"T_44f1c_row11_col6\" class=\"data row11 col6\" >0.4353</td>\n",
       "      <td id=\"T_44f1c_row11_col7\" class=\"data row11 col7\" >0.4354</td>\n",
       "      <td id=\"T_44f1c_row11_col8\" class=\"data row11 col8\" >34.6010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44f1c_level0_row12\" class=\"row_heading level0 row12\" >qda</th>\n",
       "      <td id=\"T_44f1c_row12_col0\" class=\"data row12 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_44f1c_row12_col1\" class=\"data row12 col1\" >0.7321</td>\n",
       "      <td id=\"T_44f1c_row12_col2\" class=\"data row12 col2\" >0.7908</td>\n",
       "      <td id=\"T_44f1c_row12_col3\" class=\"data row12 col3\" >0.7321</td>\n",
       "      <td id=\"T_44f1c_row12_col4\" class=\"data row12 col4\" >0.7631</td>\n",
       "      <td id=\"T_44f1c_row12_col5\" class=\"data row12 col5\" >0.7119</td>\n",
       "      <td id=\"T_44f1c_row12_col6\" class=\"data row12 col6\" >0.4641</td>\n",
       "      <td id=\"T_44f1c_row12_col7\" class=\"data row12 col7\" >0.4898</td>\n",
       "      <td id=\"T_44f1c_row12_col8\" class=\"data row12 col8\" >463.3740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2046ade8f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b00bc41a3e9420e84a9634599d440fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "print(\"Loading and preparing data...\")\n",
    "# data = prepare_data('IMDB Dataset.csv', sample_size=100)\n",
    "data = prepare_data('IMDB Dataset.csv')\n",
    "\n",
    "# Setup the classification experiment\n",
    "print(\"Setting up PyCaret classifier...\")\n",
    "clf_setup = setup_pycaret_classifier(data)\n",
    "\n",
    "# Get best individual models\n",
    "best_models = get_best_models(top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print initial model performances\n",
    "print(\"\\nInitial model performances:\")\n",
    "for i, model in enumerate(best_models, 1):\n",
    "    print(f\"\\nModel {i} - Initial Performance:\")\n",
    "    evaluate_model(model, f\"Initial Model {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the models\n",
    "tuned_models = tune_models(best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print tuned model performances\n",
    "print(\"\\nTuned model performances:\")\n",
    "for i, model in enumerate(tuned_models, 1):\n",
    "    print(f\"\\nModel {i} - Tuned Performance:\")\n",
    "    evaluate_model(model, f\"Tuned Model {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and evaluate stacking ensemble\n",
    "stacking_ensemble = create_ensemble(tuned_models)\n",
    "ensemble_predictions = evaluate_model(stacking_ensemble, \"Stacking Ensemble\")\n",
    "\n",
    "# Save the ensemble model\n",
    "print(\"\\nSaving ensemble model...\")\n",
    "save_model(stacking_ensemble, 'sentiment_classifier_ensemble')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
